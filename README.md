
# ğŸ¤– GenAI & LangChain Playground â€” Multi-LLM Integration Project

Welcome to my LangChain-powered Generative AI projects!  
This repository demonstrates my hands-on implementation and learning of modern GenAI techniques using LangChain, integrating powerful LLMs such as **OpenAI GPT-4**, **Google Gemini**, **Groq (LLaMA, Mixtral, Gemma)**, and more.

---

## ğŸ“š What I Learned and Implemented

- âœ… Learned to use **LangChain** to build modular GenAI applications from scratch.
- ğŸ”— Integrated multiple **LLM providers** â€” OpenAI, Gemini, Groq, Claude â€” using LangChain wrappers and chains.
- ğŸ” Implemented **Retrieval-Augmented Generation (RAG)** pipelines using FAISS and Chroma for knowledge-grounded responses.
- âœ¨ Explored and applied **prompt engineering**, system messages, templates, and memory-based chains.
- ğŸ§  Developed smart assistants with **ConversationalRetrievalChain**, **MultiQueryRetriever**, and **LangChain Agents**.
- ğŸ§¾ Loaded and chunked documents (PDF, TXT, HTML) to allow natural language querying over user-provided data.

---

## ğŸš€ Use Cases Demonstrated

- ğŸ§‘â€ğŸ’¼ Chatbot with context-aware responses across multiple models.
- ğŸ“„ Question answering from uploaded PDFs or local documents.
- ğŸ§  Research assistant with semantic search and summarization.
- ğŸ¤– LLM Agent that uses tools and reasoning for complex tasks.

---

## ğŸ”§ Tech Stack

| Tool | Purpose |
|------|---------|
| **LangChain** | Framework for LLM chaining and orchestration |
| **OpenAI GPT-4** | Natural language understanding & generation |
| **Google Gemini** | Advanced text + multimodal capabilities |
| **Groq** | High-speed local model inference (LLaMA, Mixtral, etc.) |
| **FAISS / Chroma** | Vector stores for RAG |
| **Python** | Backend logic and orchestration |
| **Streamlit / CLI** | Simple interface for testing chains |

---

## ğŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ app.py                 # Streamlit or CLI demo
â”œâ”€â”€ chains/               # LangChain chains and agents
â”œâ”€â”€ prompts/              # Prompt templates
â”œâ”€â”€ loaders/              # Custom document loaders
â”œâ”€â”€ utils/                # Helper functions
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project overview (this file)
```

---

## âš™ï¸ Quickstart Guide


1. **Set up the environment**
```bash
python -m venv venv
source venv/bin/activate  # or venv\Scriptsctivate
pip install -r requirements.txt
```

2. **Add your API keys**
Create a `.env` file:
```env
OPENAI_API_KEY=your-key
GOOGLE_API_KEY=your-key
GROQ_API_KEY=your-key
ANTHROPIC_API_KEY=your-key
```

3. **Run the app**
```bash
python app.py
# or streamlit run app.py
```

---

## ğŸ§  Example Chains Youâ€™ll Find Inside

- `ConversationalRetrievalChain` with memory
- `MultiQueryRetriever` for diverse document retrieval
- `LLMChain` with system prompts
- Tool-using `AgentExecutor` with function-calling LLMs

---


## ğŸ“Œ Tags & Keywords

`#LangChain` `#LLM` `#GenAI` `#OpenAI` `#GoogleGemini` `#Groq` `#PromptEngineering` `#RAG` `#AIChatbot` `#Python`

---

## ğŸ¤ Acknowledgments

Thanks to the LangChain community and documentation for making LLM integration easy and extensible.
