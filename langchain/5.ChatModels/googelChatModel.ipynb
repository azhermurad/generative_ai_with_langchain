{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9fea5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28b73aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading env varables\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a21c2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=1.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bae1ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\"what is langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ed4dd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Langchain is a framework designed to simplify the development of applications powered by large language models (LLMs). Think of it as a toolkit that provides components and chains to help you build complex applications using LLMs like GPT-3, GPT-4, and others.\\n\\nHere's a breakdown of what makes Langchain useful:\\n\\n**Core Concepts:**\\n\\n*   **Components:** These are the basic building blocks. Langchain provides pre-built modules for common tasks, such as:\\n    *   **Models:**  Wrappers for various LLMs (OpenAI, Cohere, Hugging Face, etc.) allowing you to interact with them in a consistent way.  This allows you to easily switch between different LLMs without rewriting your code.\\n    *   **Prompts:** Tools for creating and managing prompts. This includes prompt templates (for generating prompts with variables) and example selectors (for choosing the best examples to include in your prompt).\\n    *   **Chains:** Sequences of calls to LLMs or other utilities. Chains allow you to combine multiple steps into a single, coherent operation.\\n    *   **Indexes:**  Structures for indexing and retrieving data.  This is crucial for tasks like question answering over large documents.\\n    *   **Memory:**  Mechanisms for storing and retrieving information from previous interactions.  This is essential for building conversational applications.\\n    *   **Agents:**  Components that use an LLM to decide which actions to take.  Agents can use tools (like search engines or calculators) to accomplish more complex tasks.\\n    *   **Callbacks:** Mechanisms to log and monitor the execution of chains and agents.\\n\\n*   **Chains:** These are sequences of calls to LLMs or other utilities. They allow you to combine multiple steps into a single, coherent operation.  For example, you might have a chain that first summarizes a document and then answers questions about the summary.\\n\\n**Key Benefits of Using Langchain:**\\n\\n*   **Abstraction and Modularity:**  It provides a high level of abstraction, making it easier to work with LLMs without needing to delve into the low-level details of each model.  The modular design allows you to easily swap out different components and customize your applications.\\n*   **Rapid Prototyping:** Langchain provides many pre-built components and chains, which significantly speeds up the development process.\\n*   **Flexibility and Customization:**  While Langchain provides a lot of pre-built functionality, it's also highly customizable. You can easily create your own components and chains to meet your specific needs.\\n*   **Community and Ecosystem:** Langchain has a large and active community, which means there are plenty of resources available to help you get started and troubleshoot problems.\\n*   **Integration with Other Tools:** Langchain integrates with a wide range of other tools, such as vector databases (Chroma, Pinecone, FAISS), document loaders, and APIs.  This allows you to build applications that can access and process data from a variety of sources.\\n\\n**Use Cases:**\\n\\nLangchain is used for a wide variety of applications, including:\\n\\n*   **Question Answering:** Building systems that can answer questions based on a given context (e.g., a document or a website).\\n*   **Chatbots:** Creating conversational agents that can engage in natural language conversations.\\n*   **Text Summarization:**  Generating concise summaries of long documents.\\n*   **Text Generation:**  Creating new text, such as articles, poems, or code.\\n*   **Data Augmentation:** Generating synthetic data to improve the performance of machine learning models.\\n*   **Agent Development:** Building autonomous agents that can perform tasks by interacting with the world through tools and APIs.\\n\\n**In Simple Terms:**\\n\\nImagine you want to build a robot that can answer questions about a library.\\n\\n*   **Without Langchain:** You'd have to write code to connect to an LLM, write code to fetch information about the books in the library, write code to format the information for the LLM, and then write code to parse the LLM's response.\\n*   **With Langchain:** You can use Langchain's pre-built components to connect to an LLM, load the library's data into an index, create a chain that searches the index and then asks the LLM a question, and then display the LLM's response.\\n\\n**In conclusion, Langchain is a powerful framework that simplifies the development of LLM-powered applications. It provides a set of tools and abstractions that make it easier to build complex and sophisticated applications without needing to be an expert in LLMs.**\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String PromptTemplates\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d7dd0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
    "prompt = prompt_template.invoke({\"topic\":\"ball\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c389f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the baseball team hire a wizard?\\n\\nBecause they needed to improve their batting average and wanted some *batting magic!* ', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--e5962c2c-d658-485a-a9c7-fa9f3c234ac4-0', usage_metadata={'input_tokens': 6, 'output_tokens': 28, 'total_tokens': 34, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm.invoke(prompt)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a04724d",
   "metadata": {},
   "source": [
    "### ChatPromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "115c2f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e519b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\" You are a helpful, accurate, and friendly Data Science Assistant. Your job is to answer user questions related to data science, artificial intelligence (AI), and machine learning (ML), including deep learning, statistics, data analysis, tools (e.g., Python, R, TensorFlow, PyTorch, Scikit-learn), and industry practices.\n",
    "\n",
    "You should:\n",
    "\n",
    "Provide clear, concise, and technically correct answers.\n",
    "\n",
    "Explain concepts simply when asked by beginners, and use technical depth for expert-level queries.\n",
    "\n",
    "Use examples or code snippets (in Python or appropriate tools) where helpful.\n",
    "\n",
    "Avoid making up facts. If uncertain, state it clearly.\n",
    "\n",
    "Be up to date with the latest tools, techniques, and trends as of 2025.\n",
    "\n",
    "Topics may include:\n",
    "\n",
    "Supervised / Unsupervised / Reinforcement Learning\n",
    "\n",
    "Neural Networks and Deep Learning (CNNs, RNNs, Transformers, etc.)\n",
    "\n",
    "Data preprocessing and EDA\n",
    "\n",
    "Model evaluation metrics\n",
    "\n",
    "Prompt engineering and LLMs\n",
    "\n",
    "MLOps and model deployment\n",
    "\n",
    "Python, NumPy, Pandas, Scikit-learn, PyTorch, TensorFlow\n",
    "\n",
    "Kaggle competitions, notebooks, and best practices\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58fb00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", system),\n",
    "    (\"user\",\" {topic}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a23958bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain\n",
    "\n",
    "chain = prompt_template | llm\n",
    "result = chain.invoke({\"topic\": \"who are you\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f0801937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am a Data Science Assistant, an AI designed to help users with questions related to data science, artificial intelligence, and machine learning. I can explain concepts, provide code examples, discuss tools, and offer insights into industry best practices. My goal is to provide you with clear, accurate, and helpful information in these fields.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f6dc76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
